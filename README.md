# MNIST Digit Classification - MLOps Project

A complete Machine Learning Operations (MLOps) project for handwritten digit classification using the MNIST dataset. This project demonstrates the full ML lifecycle from model training to production deployment with containerization and automated pipelines.

## ğŸ¯ Project Overview

This project implements a **Convolutional Neural Network (CNN)** to classify handwritten digits (0-9) from the MNIST dataset. It includes:

- **Model Training**: PyTorch-based CNN implementation
- **Web Application**: Interactive Gradio interface for real-time predictions
- **MLOps Pipeline**: Automated training, evaluation, and deployment
- **Containerization**: Docker support with multi-stage builds
- **Cloud Deployment**: Integration with Hugging Face Spaces

## ğŸ—ï¸ Project Structure

```
nmist/
â”œâ”€â”€ train.py                 # Model training script
â”œâ”€â”€ notebook.ipynb          # Jupyter notebook for experimentation
â”œâ”€â”€ requirements.txt        # Training dependencies
â”œâ”€â”€ Dockerfile             # Multi-stage Docker build
â”œâ”€â”€ Makefile              # Automation commands
â”œâ”€â”€ App/                  # Web application
â”‚   â”œâ”€â”€ app.py           # Gradio web interface
â”‚   â”œâ”€â”€ requirements.txt # App dependencies
â”‚   â””â”€â”€ README.md       # HuggingFace Space config
â”œâ”€â”€ Data/                # MNIST dataset
â”‚   â””â”€â”€ MNIST/raw/      # Raw dataset files
â””â”€â”€ Model/              # Trained model files
    â””â”€â”€ mnist_cnn.pth  # Saved model weights
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.10+
- pip
- Docker (optional, for containerized deployment)

### 1. Install Dependencies

```bash
make install
# or
pip install -r requirements.txt
```

### 2. Train the Model

```bash
make train
# or
python train.py
```

### 3. Run the Web Application

```bash
cd App
pip install -r requirements.txt
python app.py
```

The application will be available at `http://localhost:7860`

## ğŸ”§ Model Architecture

The project uses a **SimpleCNN** architecture:

- **Input**: 28x28 grayscale images
- **Conv Layer 1**: 32 filters, 3x3 kernel, ReLU activation
- **Conv Layer 2**: 64 filters, 3x3 kernel, ReLU activation
- **MaxPooling**: 2x2 pooling after each conv layer
- **Fully Connected**: 128 neurons, ReLU activation
- **Output**: 10 classes (digits 0-9)

## ğŸ“± Web Application Features

- **Interactive Drawing Canvas**: Draw digits directly in the browser
- **Real-time Prediction**: Instant classification results
- **Probability Scores**: View confidence scores for all digit classes
- **Image Preprocessing**: Automatic normalization and resizing

## ğŸ³ Docker Deployment

### Build and Run

```bash
docker build -t mnist-app .
docker run -p 7860:7860 mnist-app
```

### Multi-stage Build Process

1. **Builder Stage**: Trains the model and generates `mnist_cnn.pth`
2. **App Stage**: Creates lightweight production image with only the application

## ğŸ› ï¸ Available Commands (Makefile)

| Command | Description |
|---------|-------------|
| `make install` | Install Python dependencies |
| `make format` | Format code with Black |
| `make train` | Train the model |
| `make eval` | Generate evaluation report |
| `make hf-login` | Login to Hugging Face |
| `make push-hub` | Upload to Hugging Face Spaces |
| `make deploy` | Full deployment pipeline |

## ğŸ“Š Model Performance

- **Training Duration**: 3 epochs
- **Optimizer**: Adam (lr=0.001)
- **Loss Function**: CrossEntropyLoss
- **Batch Size**: 64

## ğŸŒ Cloud Deployment

This project is configured for deployment on **Hugging Face Spaces**:

```bash
make deploy
```

This will:
1. Login to Hugging Face
2. Upload application files
3. Upload trained model
4. Deploy to your HF Space

## ğŸ“ Key Files

- **`train.py`**: Main training script with CNN implementation
- **`App/app.py`**: Gradio web application
- **`Dockerfile`**: Multi-stage container build
- **`Makefile`**: Automation and deployment commands
- **`notebook.ipynb`**: Jupyter notebook for experimentation

## ğŸ”„ MLOps Workflow

1. **Development**: Code in Jupyter notebook or Python scripts
2. **Training**: Automated model training with `make train`
3. **Evaluation**: Generate metrics and reports
4. **Containerization**: Docker builds for reproducible deployment
5. **Deployment**: Automated push to Hugging Face Spaces
6. **Monitoring**: Track performance and model drift

## ğŸ›¡ï¸ Requirements

### Training Environment
```
torch
torchvision
numpy
black
```

### Application Environment
```
gradio
torch
torchvision
numpy
pillow
```

## ğŸ“ Usage Examples

### Training a Model
```python
python train.py
```

### Making Predictions
```python
from train import SimpleCNN
import torch

model = SimpleCNN()
model.load_state_dict(torch.load('Model/mnist_cnn.pth'))
model.eval()

# Your prediction code here
```

### Running with Docker
```bash
docker build -t mnist-classifier .
docker run -p 7860:7860 mnist-classifier
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run `make format` to format code
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the Apache 2.0 License.

## ğŸ”— Links

- **Hugging Face Space**: [nmist](https://huggingface.co/spaces/mazenbuk/nmist)
- **Dataset**: [MNIST](http://yann.lecun.com/exdb/mnist/)
- **Framework**: [PyTorch](https://pytorch.org/)
- **Interface**: [Gradio](https://gradio.app/)

## ğŸ“š Learning Objectives

This project demonstrates:
- **Deep Learning**: CNN implementation for image classification
- **MLOps**: End-to-end ML pipeline automation
- **Web Development**: Interactive ML applications
- **DevOps**: Containerization and deployment strategies
- **Cloud Computing**: Platform-as-a-Service deployment

Perfect for learning modern MLOps practices and building production-ready ML applications!